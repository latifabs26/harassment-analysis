import tweepy
import json
import csv
import logging
from datetime import datetime
from typing import List, Dict
import os
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TwitterHarassmentCollector:
    """Collecteur simple pour les posts Twitter avec #harc√®lement"""
    
    def __init__(self):
        # R√©cup√©rer le token depuis les variables d'environnement
        self.bearer_token = os.getenv('TWITTER_BEARER_TOKEN')
        
        if not self.bearer_token:
            raise ValueError("TWITTER_BEARER_TOKEN non trouv√© dans les variables d'environnement")
        
        # Initialiser le client Twitter
        self.client = tweepy.Client(bearer_token=self.bearer_token)
        logger.info("Client Twitter initialis√© avec succ√®s")
    
    def collect_posts(self, max_results: int = 100) -> List[Dict]:
        """
        Collecte les posts Twitter avec le hashtag #harc√®lement
        
        Args:
            max_results: Nombre maximum de posts √† collecter
            
        Returns:
            Liste des posts sous forme de dictionnaires
        """
        posts = []
        
        try:
            logger.info(f"Recherche de posts avec #harc√®lement (max: {max_results})")
            
            # Recherche des tweets
            # Query: #harc√®lement ou #harcelement, pas de retweets, en fran√ßais
            query = "#harc√®lement OR #harcelement -is:retweet lang:fr"
            
            tweets = tweepy.Paginator(
                self.client.search_recent_tweets,
                query=query,
                tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations'],
                max_results=min(max_results, 100)  # API limite √† 100 par requ√™te
            ).flatten(limit=max_results)
            
            for tweet in tweets:
                # Cr√©er un dictionnaire simple pour chaque post
                post_data = {
                    'id': str(tweet.id),
                    'text': tweet.text,
                    'author_id': f"user_{tweet.author_id}",  # Anonymis√©
                    'created_at': tweet.created_at.isoformat(),
                    'likes': tweet.public_metrics['like_count'] if tweet.public_metrics else 0,
                    'retweets': tweet.public_metrics['retweet_count'] if tweet.public_metrics else 0,
                    'replies': tweet.public_metrics['reply_count'] if tweet.public_metrics else 0,
                    'url': f"https://twitter.com/user/status/{tweet.id}",
                    'collected_at': datetime.now().isoformat()
                }
                
                posts.append(post_data)
                
            logger.info(f"‚úÖ {len(posts)} posts collect√©s avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la collecte: {e}")
            
        return posts
    
    def save_to_json(self, posts: List[Dict], filename: str = "harassment_posts.json"):
        """Sauvegarder les posts en JSON"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(posts, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Donn√©es sauvegard√©es dans {filename}")
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde JSON: {e}")
    
    def save_to_csv(self, posts: List[Dict], filename: str = "harassment_posts.csv"):
        """Sauvegarder les posts en CSV"""
        if not posts:
            logger.warning("Aucun post √† sauvegarder")
            return
            
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=posts[0].keys())
                writer.writeheader()
                writer.writerows(posts)
            logger.info(f"‚úÖ Donn√©es sauvegard√©es dans {filename}")
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde CSV: {e}")
    
    def print_stats(self, posts: List[Dict]):
        """Afficher des statistiques simples"""
        if not posts:
            logger.info("Aucun post √† analyser")
            return
            
        total_likes = sum(post['likes'] for post in posts)
        total_retweets = sum(post['retweets'] for post in posts)
        total_replies = sum(post['replies'] for post in posts)
        
        logger.info("üìä STATISTIQUES:")
        logger.info(f"   Total posts: {len(posts)}")
        logger.info(f"   Total likes: {total_likes}")
        logger.info(f"   Total retweets: {total_retweets}")
        logger.info(f"   Total r√©ponses: {total_replies}")
        
        # Afficher quelques exemples
        logger.info("\nüìù EXEMPLES DE POSTS:")
        for i, post in enumerate(posts[:3]):  # Afficher les 3 premiers
            text_preview = post['text'][:100] + "..." if len(post['text']) > 100 else post['text']
            logger.info(f"   {i+1}. {text_preview}")

def main():
    """Fonction principale"""
    print("üöÄ D√©marrage du collecteur Twitter #harc√®lement")
    print("=" * 50)
    
    try:
        # Initialiser le collecteur
        collector = TwitterHarassmentCollector()
        
        # Collecter les posts
        posts = collector.collect_posts(max_results=50)  # Commencer petit
        
        if posts:
            # Sauvegarder les donn√©es
            collector.save_to_json(posts)
            collector.save_to_csv(posts)
            
            # Afficher les statistiques
            collector.print_stats(posts)
        else:
            logger.warning("‚ö†Ô∏è Aucun post collect√©")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur dans le programme principal: {e}")
        print("\nüí° AIDE:")
        print("1. V√©rifiez que TWITTER_BEARER_TOKEN est d√©fini dans votre fichier .env")
        print("2. Assurez-vous d'avoir acc√®s √† l'API Twitter")

if __name__ == "__main__":
    main()